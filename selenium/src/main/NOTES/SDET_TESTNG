
TEST NG ------> Test New Generation

java based unit test tool

Adv
-----
1 Test Cases & test suites
2 Grouping of test case
3 Prioritize
4 Parameterization
5 Parallel test
6 Reports

Testng config
-----------------

1 install testng
2 add testng library to build path / add testng dependency in pom.xml

@Test  -----> annotation    [ Replacement of main method ]

testng method not return any thing
1 Testng by default it execute in test case in  alphabetical order                         1 ----->  default - alphabet
2 @Test(priority = num) controls the order of execution                 -                  2 ----->  priority - control execution
3 once you provide priority to the test methods then order of methods , is not considered .3 ----->  in priority order is not matter
4 priorities can be random numbers( no need to have consecutive numbers )                  4 ----->  priority have any num not consecutive
5 if you dont provide priority then default value is zero ( 0 ).                           5 ----->  we dont provide priority defaut is 0
6 if the priorities are same then again execute methods in alphabetical order.             6 ----->  if priority should same alphabet order only again
7 Negative values are allowed in priority.                                                 7 ----->  priority allow negative values also
8 Testng execute test method only if they are having @Test annotation.                     8 ----->  testng work only with @Test annotation.


Execute test cases using testng XML file
------------------------------------------
1 Generate automatically
2 manually

Test suit ------> group of Test cases

Test suite ----> multiple (Test cases) ----> Test steps
Xml file ----> classes ----> Test methods

2 things achived through xml
---------------------
1 execute group of test cases as a 1 suite
2 we can generate test reports (default)



Annotations      --------->   it control the order of execution
------------

    @BeforeMethod** → Runs before each @Test method**.

    @AfterMethod** → Runs after each @Test method**.

    @BeforeClass** → Runs once before the first @Test in the class**.

    @AfterClass** → Runs **once after all @Test in the class**.

    @BeforeTest** → Runs **before all @Test methods inside `<test>` tag in XML**.

*   @AfterTest** → Runs **after all @Test methods inside `<test>` tag in XML**.

    @BeforeSuite** → Runs **once before the entire suite starts**.

*   @AfterSuite** → Runs **once after the entire suite ends**.

----------------

⚡ Easy way to remember:

* **Method → around each test method**
* **Class → around class**
* **Test → around `<test>` in XML**
* **Suite → around whole suite**

-------------------------------------------------------------------------------------------------
Annotations
-------------
@Test

@BeforeMethod
@AfterMethod

@BeforeClass  ------> single class
@AfterClass

@BeforeTest   ------> multiple class
@AfterTest

@BeforeSuit
@AfterSuite


Tc1 -----> method
----
1 login ----> @BeforeMethod
2 Search ----> @Test
3 Logout ----> @AfterMethod
4 Login ----> @BeforeMethod
5 Adv Search ----> @Test
6 Logout ---->  @AfterMethod

Tc2  --------> class
----
1 login ----> @BeforeClass
2 Search ----> @Test
5 Adv Search ----> @Test
6  Logout ----> @AfterClass

xml ----> test
------

<suite name="my suit">             ---------> BeforeSuite

    <test name="my test1">        --------> TestBefore
        <classes>
            <class name="abc"/>
        </classes>               ---------> TestAfter
    </test>

    test name="my test2">           --------> TestBefore
            <classes>
                <class name="xyz"/>
            </classes>
        </test>                     ---------> TestAfter

</suite>                        ---------> AfterSuite

===========================================================================================================

Assert is an pre defined class which we used for access tha different type of assertion

Assertion - validation point   ------->   import org.testng.Assert;

2 kind of assertions
---------------------
1 Hard assertion
   --------------
    we can access form Assert class methods are static
    if hard assertion failed the rest of statement will not be executed

Static methods
------------------

Assert.assertEquals();
Assert.assertNotEquals();
Assert.assertTrue(true);
Assert.assertTrue(1==1);
Assert.assertFalse(1==2);

Assert.fail();

why hard assertion is not always recommended ?

void test()
{
    S.o.p("test")
    S.o.p("test")
    Assert.assertEquals(1,2);  if the condition pass all statements will run with out error
                               if the condition fail remaining statements is not run
                               last step only assertion  but 99% of time we use hard assertion
    S.o.p("test")  // not run
    S.o.p("test")  // not run
}
----------------------------------------------------------------------------------------------------------------
2 Soft assertion
  ---------------
  we can access softAssert object
    if soft Assert got fail then rest of the statements still execute

    assert are non static

   SoftAssert sa = new SoftAssert();

   void test()
   {
       S.o.p("test")
       S.o.p("test")

       SoftAssert sa = new SoftAssert();
       sa.assertEquals(1,2);       Even if the condition fail rest of the condition should run and execute the result

       S.o.p("test")
       S.o.p("test")

       sa.assertAll(); // mandatory
   }
========================================================================================================================

Dependency Methods
-------------------

dependsOnMethods={"methods1","methods2"}

grouping
----------
grouping should be execute only by xml files

class file -----> methods

class1 = m1,m2,m3
class2 = m4,m5,m6..
class3 = m7,m8,m9..
---------

sanity
regression
functional

loginby fb  - sanity
loginby mail  - sanity
loginby twitter - sanity

signup fb - regression
signup twitter - regression
signup mail - regression

pay rupee - sanity , regression (functional)
pay dollar - sanity , regression (functional)

// ! check group.xml created

1 all sanity teste
2 all regression tests
3 all sanity but not regression
4 all regression but not sanity
5 all method which are belong to both sanity and regression

=======================================================================================================================

PARAMETERIZATION
-------------------

1 @DataProvider ----- > (Data driven testing)  it don't want any looping statements to run multiple test cases multiple times

    if we have multiple data provider

    test1(data provider = "dp1")
    test2(data provider = "dp2")

    data provider(name = "dp1")
    data provider(name = "dp2")

    in realtime separate class for Data provider for access where ever we want


    @DataProvider(name = "dp" , indices = {4}) ---------> indices is used for run the specific data we want to run

    @DataProvider(name = "dp" , indices = {0,4}) -------->  here 0'th index element and  4'th index element should execute


------------------------------------------------------------------------------------------------------------------------------------------

2 using xml file to pass parameterization ----->  parallel testing

parallel test using xml file
-------------------------------

step 1 : created test case
step 2 : create xml file then run test case through xml
step 3 : passed browser name , url as parameter from xml file to setup() method
step 4 : execute test case on chrome & edge ,firefox (serial execution)
step 5 : execute test case on chrome & edge ,firefox (parallel execution)

Thread count = "5" ----> 5 memory locator should be create [In selenium not more then 5 thread value is allowed]

In parallel test ( Time taken is less )

In series ( Test time taken is more )
---------------------------------------------------------------------------------------------------------------------------------------------

TestNG Listeners
----------------------
we can perform post action from using lister -------> these case execute based on the previous case result

1 create test case
2 create listener class
3 create xml and include both test case & listener class


2 ways to implement listener class
--------------------------------------
Method 1
---------
class myListener implements ITestListener
{

}
Method 2
-----------
class myListener extends TestListenerAdapter
{

}
-------------------------------------------------------------------------------------------
NOTES: IN ITestListener

ITestListener:
----------------
Event Monitoring: It provides callback methods that are automatically invoked at different points in a test's lifecycle, such as when a test starts, succeeds, fails, or is skipped.
Custom Actions: The methods within the ITestListener interface can be overridden to implement custom logic. This allows for actions like:
Logging test status and details.
Taking screenshots on test failure.
Generating custom reports.
Performing setup or teardown operations related to individual test methods.

Methods: The ITestListener interface includes methods such as:
------------------------------------------------------------------

onStart(ITestContext context): Invoked before any test method in a test context starts.

onFinish(ITestContext context): Invoked after all test methods in a test context have finished.

onTestStart(ITestResult result): Invoked at the beginning of each individual test method.
onTestSuccess(ITestResult result): Invoked when a test method successfully completes.

onTestFailure(ITestResult result): Invoked when a test method fails.

onTestSkipped(ITestResult result): Invoked when a test method is skipped.
onTestFailedButWithinSuccessPercentage(ITestResult result): Invoked when a test method fails but is still considered successful based on a defined success percentage.

Implementation: To use ITestListener, a class must implement the ITestListener interface and override the desired methods. This listener class can then be registered with TestNG, either through the testng.xml file or by using the @Listeners annotation on the test class.

-------------------------------------------------------------------------------------------------------------------

Extent Reports
---------------------
Extent Reports is a popular reporting library used in conjunction with TestNG and other testing frameworks to generate detailed and visually appealing test execution reports.
It provides a way to document the results of automated tests,
making it easier to analyze and share test outcomes with stakeholders.

Key Features of Extent Reports: (3 main class)
---------------------------
ExtentSparkReporter:  UI
ExtentReports:  populate common info (tester name , OS , browser name)
ExtentTest:

